

> 原文：[09讲普通索引和唯一索引，应该怎么选择](https://funnylog.gitee.io/mysql45/09%E8%AE%B2%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%EF%BC%8C%E5%BA%94%E8%AF%A5%E6%80%8E%E4%B9%88%E9%80%89%E6%8B%A9.html)

# 什么是change buffer

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在`change buffer`中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行`change buffer`中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。

> 注意：需要说明的是，虽然名字叫作change buffer，实际上它是可以持久化的数据。也就是说，change buffer在内存中有拷贝，也会被写入到磁盘上。

显然，如果能够将更新操作先记录在change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率。

# 什么是merge

将`change buffer`中的操作应用到原数据页，得到最新结果的过程称为`merge`。除了访问这个数据页会触发`merge`外，系统有后台线程会定期`merge`。在数据库正常关闭（shutdown）的过程中，也会执行`merge`操作。

# merge的过程是否会把数据直接写回磁盘？

`merge`的执行流程是这样的：

1. 从磁盘读入数据页到内存（老版本的数据页）；

2. 从`change buffer`里找出这个数据页的`change buffer` 记录(可能有多个），依次应用，得到新版数据页；

3. 写`redo log`。这个`redo log`包含了数据的变更和`change buffer`的变更。

到这里`merge`过程就结束了。这时候，新版数据页和内存中`change buffer`对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。

> mysql脏页：  
> 当内存数据页和磁盘数据页上的内容不一致时，我们称这个内存页为 **脏页**；  
> 内存数据写入磁盘后，内存页上的数据和磁盘页上的数据就一致了，我们称这个内存页为干净页。  
> 不管是脏页 还是 干净页 ，他们都在内存中。

# change buffer的使用场景

对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入(4,400)这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用`change buffer`了。

因此，唯一索引的更新就不能使用`change buffer`，实际上也只有普通索引可以使用。

因为`merge`的时候是真正进行数据更新的时刻，而`change buffer`的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做`merge`之前，`change buffer`记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。

因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。

反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在`change buffer`，但之后由于马上要访问这个数据页，会立即触发`merge`过程。这样随机访问IO的次数不会减少，反而增加了`change buffer`的维护代价。所以，对于这种业务模式来说，`change buffer`反而起到了副作用。

# change buffer 和 redo log

> [一条SQL更新语句是如何执行的](https://github.com/ProgrammerGoGo/document/blob/main/MySQL/%E4%B8%80%E6%9D%A1SQL%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.md)

现在，我们要在表上执行这个插入语句：  
```sql
insert into t(id,k) values(id1,k1),(id2,k2);
```
这里，我们假设当前k索引树的状态，查找到位置后，k1所在的数据页在内存(InnoDB buffer pool)中，k2所在的数据页不在内存中。则带`change buffer`的更新状态图如下。

![带change buffer的更新过程](image/带change%20buffer的更新过程.jpg)

分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。

这条更新语句做了如下的操作（按照图中的数字顺序）：

1. Page 1在内存中，直接更新内存；

2. Page 2没有在内存中，就在内存的change buffer区域，记录下“我要往Page 2插入一行”这个信息

3. 将上述两个动作记入redo log中（图中3和4）。

做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。

同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。

那在这之后的读请求，要怎么处理呢？

比如，我们现在要执行查询语句。

```sql
select * from t where k in (k1, k2)
```

这两个读请求的流程图如下。

![1](image/带change%20buffer的读过程.jpg)

如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。所以，我在图中就没画出这两部分。

从图中可以看到：

读Page 1的时候，直接从内存返回。（那么`WAL`之后如果读数据，是不是一定要读盘，是不是一定要从`redo log`里面把数据更新以后才可以返回？其实是不用的。）你可以看一下上图的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。

要读Page 2的时候，需要把Page 2从磁盘读入内存中，然后应用`change buffer`里面的操作日志，生成一个正确的版本并返回结果。

可以看到，直到需要读Page 2的时候，这个数据页才会被读入内存。

所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，`redo log` 主要节省的是随机写磁盘的IO消耗（转成顺序写），而`change buffer`主要节省的则是随机读磁盘的IO消耗。

# 问题1：change buffer一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致change buffer丢失呢？change buffer丢失可不是小事儿，再从磁盘读入数据可就没有了merge过程，就等于是数据丢失了。会不会出现这种情况呢？

不会丢失。

虽然是只更新内存，但是在事务提交的时候，我们把`change buffer`的操作也记录到`redo log`里了，所以崩溃恢复的时候，`change buffer`也能找回来。

# 问题2：merge 的过程是否会把数据直接写回磁盘？

`merge`的执行流程是这样的：

1. 从磁盘读入数据页到内存（老版本的数据页）；

2. 从`change buffer`里找出这个数据页的`change buffer` 记录(可能有多个），依次应用，得到新版数据页；

3. 写`redo log`。这个`redo log`包含了数据的变更和`change buffer`的变更。

到这里merge过程就结束了。这时候，数据页和内存中`change buffer`对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。
